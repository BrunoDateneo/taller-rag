{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8c7JkDM9-mG"
      },
      "source": [
        "# Bloque 1 췅 쯈u칠 es Retrieval-Augmented Generation (RAG)?\n",
        "\n",
        "Este bloque introduce los conceptos esenciales de un flujo RAG y c칩mo cada componente contribuye a obtener respuestas mejor informadas a partir de fuentes propias.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsxKESRP9-mH"
      },
      "source": [
        "## 쯇or qu칠 RAG?\n",
        "\n",
        "Los modelos de lenguaje grandes (LLM) poseen conocimiento general, pero no siempre est치n actualizados ni conocen los detalles internos de una organizaci칩n. Retrieval-Augmented Generation (RAG) permite enriquecer las respuestas de un modelo con informaci칩n espec칤fica proveniente de una base de conocimiento curada.\n",
        "\n",
        "En otras palabras, RAG combina dos mundos:\n",
        "- **Recuperaci칩n**: localizar fragmentos relevantes en documentos propios.\n",
        "- **Generaci칩n**: redactar una respuesta usando tanto la pregunta como los fragmentos recuperados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-E23Nee9-mH"
      },
      "source": [
        "## Componentes de un sistema RAG\n",
        "\n",
        "1. **Fuentes de conocimiento**: documentos, p치ginas web, manuales o bases de datos que contienen la informaci칩n confiable.\n",
        "2. **Ingesta y limpieza**: procesos que normalizan, eliminan ruido y preparan el texto.\n",
        "3. **Chunking**: divisi칩n en fragmentos manejables (chunks) que capturen ideas completas.\n",
        "4. **Modelos de embeddings**: convierten cada fragmento en un vector num칠rico que preserva significado.\n",
        "5. **Base vectorial**: almacena los vectores y permite realizar b칰squedas por similitud.\n",
        "6. **Recuperador**: dada una consulta, encuentra los vectores m치s cercanos.\n",
        "7. **Generador**: redacta la respuesta final usando la consulta y los fragmentos recuperados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOJkX9v69-mI"
      },
      "source": [
        "## Flujo t칤pico de extremo a extremo\n",
        "\n",
        "1. Se seleccionan y preparan las fuentes confiables.\n",
        "2. Se crean fragmentos y sus embeddings.\n",
        "3. Se almacenan en una base vectorial.\n",
        "4. Una pregunta del usuario se transforma en vector.\n",
        "5. Se recuperan los fragmentos m치s similares.\n",
        "6. Un modelo genera una respuesta apoy치ndose en esos fragmentos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zpfIr-69-mI"
      },
      "source": [
        "## Actividad pr치ctica: simulaci칩n de vector search\n",
        "\n",
        "Trabajaremos con un ejemplo muy simple usando vectores predefinidos que preservan relaciones sem치nticas. En sistemas reales, estos vectores se generan mediante modelos de transformers entrenados que capturan el significado de las palabras, pero aqu칤 usaremos vectores ya creados para entender el concepto sin ejecutar ning칰n modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5DZVJLa9-mI"
      },
      "source": [
        "### Paso 1. Definir una base de conocimiento simple\n",
        "\n",
        "Trabajaremos con un corpus muy b치sico de solo 3 documentos cortos para entender el concepto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvc1OqAc9-mI",
        "outputId": "a4e1b5d1-5a91-41d6-b261-63535041b4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos disponibles: 3\n",
            "  - doc1: Los gatos son mascotas populares.\n",
            "  - doc2: Los perros tambi칠n son mascotas comunes.\n",
            "  - doc3: La programaci칩n requiere pr치ctica constante.\n"
          ]
        }
      ],
      "source": [
        "corpus = [\n",
        "    {\n",
        "        \"id\": \"doc1\",\n",
        "        \"contenido\": \"Los gatos son mascotas populares.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc2\",\n",
        "        \"contenido\": \"Los perros tambi칠n son mascotas comunes.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"doc3\",\n",
        "        \"contenido\": \"La programaci칩n requiere pr치ctica constante.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"Documentos disponibles: {len(corpus)}\")\n",
        "for doc in corpus:\n",
        "    print(f\"  - {doc['id']}: {doc['contenido']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq7yxVDW9-mI"
      },
      "source": [
        "### Paso 2. Fragmentar y tokenizar\n",
        "\n",
        "Cada documento ya es una frase completa, as칤 que simplemente lo dividiremos en palabras (tokens).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2Ju2fp-9-mI",
        "outputId": "18af19d3-f474-48fb-f2cc-c2c77c65f639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks generados: 3\n",
            "\n",
            "doc1: Los gatos son mascotas populares.\n",
            "  Tokens: ['los', 'gatos', 'son', 'mascotas', 'populares']\n",
            "\n",
            "doc2: Los perros tambi칠n son mascotas comunes.\n",
            "  Tokens: ['los', 'perros', 'tambi칠n', 'son', 'mascotas', 'comunes']\n",
            "\n",
            "doc3: La programaci칩n requiere pr치ctica constante.\n",
            "  Tokens: ['la', 'programaci칩n', 'requiere', 'pr치ctica', 'constante']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"Convierte el texto en una lista de tokens (palabras) limpias, incluyendo signos de pregunta como tokens separados.\"\"\"\n",
        "    # Reemplazar signos de puntuaci칩n con espacios para que se separen durante el split\n",
        "    cleaned = text.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"?\", \" ? \").replace(\"쯒", \" \")\n",
        "    return cleaned.split()\n",
        "\n",
        "chunks = []\n",
        "for doc in corpus:\n",
        "    tokens = tokenize(doc[\"contenido\"])\n",
        "    chunks.append({\n",
        "        \"doc_id\": doc[\"id\"],\n",
        "        \"fragmento\": doc[\"contenido\"],\n",
        "        \"tokens\": tokens,\n",
        "    })\n",
        "\n",
        "print(f\"Chunks generados: {len(chunks)}\\n\")\n",
        "for chunk in chunks:\n",
        "    print(f\"{chunk['doc_id']}: {chunk['fragmento']}\")\n",
        "    print(f\"  Tokens: {chunk['tokens']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt4TlzPH9-mJ"
      },
      "source": [
        "### Paso 3. Embeddings predefinidos\n",
        "\n",
        "En sistemas reales, los modelos de transformers (como BERT, GPT, etc.) generan vectores que capturan el significado de las palabras. Palabras con significados similares tienen vectores cercanos en el espacio.\n",
        "\n",
        "Aqu칤 usaremos vectores predefinidos que ya preservan estas relaciones sem치nticas. Por ejemplo:\n",
        "- \"gatos\" y \"perros\" (ambas son mascotas) tendr치n vectores similares\n",
        "- \"mascotas\" y \"animales\" tendr치n vectores cercanos\n",
        "- \"programaci칩n\" tendr치 un vector diferente (tema distinto)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNx7N7669-mJ",
        "outputId": "efb7aff8-1f08-4778-ae8f-d5f955ee7225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings predefinidos (vectores normalizados):\n",
            "\n",
            "Palabras relacionadas con mascotas:\n",
            "  'gatos':    [0.5728919  0.50128041 0.64450339 0.07161149 0.        ]\n",
            "  'perros':   [0.5728919  0.50128041 0.07161149 0.64450339 0.        ]\n",
            "  'mascotas': [0.7049344  0.62660836 0.23497813 0.23497813 0.        ]\n",
            "\n",
            "Palabras relacionadas con programaci칩n:\n",
            "  'programaci칩n': [0.11043153 0.         0.         0.         0.99388373]\n",
            "  'pr치ctica':     [0.         0.31622777 0.         0.         0.9486833 ]\n",
            "\n",
            "Nota: Los vectores de 'gatos' y 'perros' ahora tienen valores m치s distintivos en sus dimensiones espec칤ficas (Dim3 para gatos, Dim4 para perros) aunque mantienen similitud en las dimensiones de 'animal' y 'mascota'.\n",
            "      'programaci칩n' sigue siendo un tema diferente con alta carga en Dim5.\n"
          ]
        }
      ],
      "source": [
        "# Embeddings predefinidos que preservan relaciones sem치nticas\n",
        "# En la pr치ctica, estos vectores ser칤an generados por un modelo transformer entrenado\n",
        "\n",
        "# Ahora usamos vectores de dimensi칩n 5 para permitir una mejor diferenciaci칩n.\n",
        "# Dimensi칩n 1: Animal general / Ser vivo\n",
        "# Dimensi칩n 2: Caracter칤stica de mascota\n",
        "# Dimensi칩n 3: Caracter칤stica espec칤fica de GATO\n",
        "# Dimensi칩n 4: Caracter칤stica espec칤fica de PERRO\n",
        "# Dimensi칩n 5: Caracter칤stica espec칤fica de Programaci칩n\n",
        "import numpy as np\n",
        "\n",
        "embeddings_dict = {\n",
        "    \"los\": np.array([0.1, 0.0, 0.0, 0.0, 0.0]),\n",
        "    \"gatos\": np.array([0.8, 0.7, 0.9, 0.1, 0.0]),      # Animal, Mascota, Gato-espec칤fico\n",
        "    \"son\": np.array([0.0, 0.1, 0.0, 0.0, 0.0]),\n",
        "    \"mascotas\": np.array([0.9, 0.8, 0.3, 0.3, 0.0]),  # Animal, Mascota, neutral en especie\n",
        "    \"populares\": np.array([0.2, 0.3, 0.1, 0.1, 0.0]),\n",
        "    \"perros\": np.array([0.8, 0.7, 0.1, 0.9, 0.0]),  # Animal, Mascota, Perro-espec칤fico\n",
        "    \"tambi칠n\": np.array([0.0, 0.1, 0.0, 0.0, 0.0]),\n",
        "    \"comunes\": np.array([0.2, 0.3, 0.1, 0.1, 0.0]),\n",
        "    \"la\": np.array([0.1, 0.0, 0.0, 0.0, 0.0]),\n",
        "    \"programaci칩n\": np.array([0.1, 0.0, 0.0, 0.0, 0.9]),  # Tema diferente, Programaci칩n-espec칤fico\n",
        "    \"requiere\": np.array([0.0, 0.1, 0.0, 0.0, 0.3]),\n",
        "    \"pr치ctica\": np.array([0.0, 0.2, 0.0, 0.0, 0.6]),\n",
        "    \"constante\": np.array([0.0, 0.1, 0.0, 0.0, 0.4]),\n",
        "}\n",
        "\n",
        "# Normalizar todos los vectores\n",
        "for palabra in embeddings_dict:\n",
        "    norm = np.linalg.norm(embeddings_dict[palabra])\n",
        "    if norm > 0:\n",
        "        embeddings_dict[palabra] = embeddings_dict[palabra] / norm\n",
        "\n",
        "print(\"Embeddings predefinidos (vectores normalizados):\")\n",
        "print(\"\\nPalabras relacionadas con mascotas:\")\n",
        "print(f\"  'gatos':    {embeddings_dict['gatos']}\")\n",
        "print(f\"  'perros':   {embeddings_dict['perros']}\")\n",
        "print(f\"  'mascotas': {embeddings_dict['mascotas']}\")\n",
        "\n",
        "print(\"\\nPalabras relacionadas con programaci칩n:\")\n",
        "print(f\"  'programaci칩n': {embeddings_dict['programaci칩n']}\")\n",
        "print(f\"  'pr치ctica':     {embeddings_dict['pr치ctica']}\")\n",
        "\n",
        "print(\"\\nNota: Los vectores de 'gatos' y 'perros' ahora tienen valores m치s distintivos en sus dimensiones espec칤ficas (Dim3 para gatos, Dim4 para perros) aunque mantienen similitud en las dimensiones de 'animal' y 'mascota'.\")\n",
        "print(\"      'programaci칩n' sigue siendo un tema diferente con alta carga en Dim5.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SR2Fteg9-mJ"
      },
      "source": [
        "### Paso 4. Convertir chunks en vectores\n",
        "\n",
        "Para representar un fragmento completo (que tiene m칰ltiples palabras), calcularemos el promedio de los vectores de todas sus palabras y luego lo normalizamos. Esto nos da un 칰nico vector que representa el significado del fragmento completo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRw8n6vb9-mJ",
        "outputId": "426ce09a-103c-4af2-8549-2b2c712ceca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc1: Los gatos son mascotas populares.\n",
            "  Vector: [0.66145139 0.68707912 0.26931279 0.13369728 0.        ]\n",
            "\n",
            "doc2: Los perros tambi칠n son mascotas comunes.\n",
            "  Vector: [0.56279391 0.7860125  0.11375592 0.22914397 0.        ]\n",
            "\n",
            "doc3: La programaci칩n requiere pr치ctica constante.\n",
            "  Vector: [0.27004276 0.21278667 0.         0.         0.9390414 ]\n",
            "\n",
            "Total de vectores: (3, 5)\n"
          ]
        }
      ],
      "source": [
        "def chunk_to_vector(tokens, embeddings_dict):\n",
        "    \"\"\"\n",
        "    Convierte una lista de tokens en un vector promediando los embeddings de cada palabra.\n",
        "    Si una palabra no est치 en el diccionario, se omite.\n",
        "    \"\"\"\n",
        "    # Asumiendo que todos los embeddings en embeddings_dict tienen la misma dimensi칩n.\n",
        "    # Si no hay tokens, o si el diccionario est치 vac칤o, devuelve un vector de ceros de la dimensi칩n correcta.\n",
        "    if not tokens or not embeddings_dict:\n",
        "        # Determina la dimensi칩n a partir de un embedding existente o usa un valor predeterminado (e.g., 5)\n",
        "        if embeddings_dict:\n",
        "            sample_vector = next(iter(embeddings_dict.values()))\n",
        "            return np.zeros(len(sample_vector))\n",
        "        else:\n",
        "            return np.zeros(5) # Dimensi칩n por defecto si no hay embeddings\n",
        "\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in embeddings_dict:\n",
        "            vectors.append(embeddings_dict[token])\n",
        "\n",
        "    if not vectors:\n",
        "        # Si no se encontraron palabras en el diccionario, devuelve un vector de ceros\n",
        "        sample_vector = next(iter(embeddings_dict.values()))\n",
        "        return np.zeros(len(sample_vector))\n",
        "\n",
        "    # Promedio de los vectores de palabras\n",
        "    vector_promedio = np.mean(vectors, axis=0)\n",
        "\n",
        "    # Normalizar el vector resultante\n",
        "    norm = np.linalg.norm(vector_promedio)\n",
        "    if norm > 0:\n",
        "        vector_promedio = vector_promedio / norm\n",
        "\n",
        "    return vector_promedio\n",
        "\n",
        "# Convertir todos los chunks a vectores\n",
        "chunk_vectors = []\n",
        "for chunk in chunks:\n",
        "    vector = chunk_to_vector(chunk[\"tokens\"], embeddings_dict)\n",
        "    chunk_vectors.append(vector)\n",
        "    print(f\"{chunk['doc_id']}: {chunk['fragmento']}\")\n",
        "    print(f\"  Vector: {vector}\\n\")\n",
        "\n",
        "chunk_vectors = np.array(chunk_vectors)\n",
        "print(f\"Total de vectores: {chunk_vectors.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12puxVny9-mJ"
      },
      "source": [
        "### Paso 5. Recuperar fragmentos por similitud\n",
        "\n",
        "Compararemos la representaci칩n vectorial de la pregunta con cada chunk usando similitud coseno. Esta m칠trica mide el 치ngulo entre dos vectores: valores cercanos a 1 indican alta similitud, mientras que valores cercanos a 0 indican baja similitud.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHuvRnof9-mJ",
        "outputId": "ca58a49d-cfec-4087-d01d-7b11cc9cf1da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== MOSTRANDO RESULTADOS PARA LA CONSULTA: '쯈u칠 son las mascotas?' (Top 3 fragmentos) ====\n",
            "\n",
            "\n",
            "--- INICIO DEL PROCESO DE RECUPERACI칍N (RETRIEVAL) ---\n",
            "Paso 1: Procesando la consulta original: '쯈u칠 son las mascotas?'\n",
            "  -> Tokens de la consulta: ['쯤u칠', 'son', 'las', 'mascotas?']\n",
            "  -> Vector (embedding) de la consulta: [0. 1. 0. 0. 0.]\n",
            "\n",
            "Paso 2: Calculando la similitud coseno con cada fragmento del corpus:\n",
            "  -> Similitud con Doc ID 'doc1' ('Los gatos son mascotas populares.'): 0.6871\n",
            "  -> Similitud con Doc ID 'doc2' ('Los perros tambi칠n son mascotas comunes.'): 0.7860\n",
            "  -> Similitud con Doc ID 'doc3' ('La programaci칩n requiere pr치ctica constante.'): 0.2128\n",
            "  -> Puntuaciones de similitud de todos los fragmentos: [0.6870791209916813, 0.7860124955864106, 0.2127866687378167]\n",
            "\n",
            "Paso 3: Ordenando los fragmentos por similitud (de mayor a menor):\n",
            "  -> Rank #1: Doc ID 'doc2' (Similitud: 0.7860)\n",
            "  -> Rank #2: Doc ID 'doc1' (Similitud: 0.6871)\n",
            "  -> Rank #3: Doc ID 'doc3' (Similitud: 0.2128)\n",
            "  -> Lista de fragmentos clasificados (칤ndice original del chunk, puntuaci칩n de similitud): [(1, 0.7860124955864106), (0, 0.6870791209916813), (2, 0.2127866687378167)]\n",
            "\n",
            "Paso 4: Seleccionando los top 3 fragmentos m치s relevantes:\n",
            "  -> Seleccionado #1 (Similitud: 0.7860): Doc ID 'doc2' - 'Los perros tambi칠n son mascotas comunes.'\n",
            "  -> Seleccionado #2 (Similitud: 0.6871): Doc ID 'doc1' - 'Los gatos son mascotas populares.'\n",
            "  -> Seleccionado #3 (Similitud: 0.2128): Doc ID 'doc3' - 'La programaci칩n requiere pr치ctica constante.'\n",
            "\n",
            "--- FIN DEL PROCESO DE RECUPERACI칍N ---\n",
            "\n",
            "\n",
            "===== RESULTADOS FINALES DE LA RECUPERACI칍N =====\n",
            "\n",
            "-------------------- RESULTADO RECUPERADO #1 --------------------\n",
            "  Posici칩n (Rank): 1\n",
            "  Similitud con la consulta: 78.6%\n",
            "  Documento ID: doc2\n",
            "  Fragmento recuperado: 'Los perros tambi칠n son mascotas comunes.'\n",
            "------------------------------------------------------------------\n",
            "\n",
            "-------------------- RESULTADO RECUPERADO #2 --------------------\n",
            "  Posici칩n (Rank): 2\n",
            "  Similitud con la consulta: 68.7%\n",
            "  Documento ID: doc1\n",
            "  Fragmento recuperado: 'Los gatos son mascotas populares.'\n",
            "------------------------------------------------------------------\n",
            "\n",
            "-------------------- RESULTADO RECUPERADO #3 --------------------\n",
            "  Posici칩n (Rank): 3\n",
            "  Similitud con la consulta: 21.3%\n",
            "  Documento ID: doc3\n",
            "  Fragmento recuperado: 'La programaci칩n requiere pr치ctica constante.'\n",
            "------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity(vector_a, vector_b):\n",
        "    \"\"\"Calcula la similitud coseno entre dos vectores.\"\"\"\n",
        "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
        "    if denom == 0:\n",
        "        # Si uno de los vectores es cero, la similitud es 0.0 para evitar divisi칩n por cero.\n",
        "        return 0.0\n",
        "    return float(np.dot(vector_a, vector_b) / denom)\n",
        "\n",
        "def retrieve(query, top_k=3):\n",
        "    \"\"\"\n",
        "    Recupera los top_k chunks m치s similares a la consulta.\n",
        "    Detalla los pasos del algoritmo para una mejor comprensi칩n.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- INICIO DEL PROCESO DE RECUPERACI칍N (RETRIEVAL) ---\")\n",
        "    print(f\"Paso 1: Procesando la consulta original: '{query}'\")\n",
        "\n",
        "    # Paso 1.1: Tokenizar la consulta\n",
        "    # Se convierte el texto de la consulta en una lista de palabras (tokens).\n",
        "    query_tokens = tokenize(query)\n",
        "    print(f\"  -> Tokens de la consulta: {query_tokens}\")\n",
        "\n",
        "    # Paso 1.2: Convertir la consulta en un vector (embedding)\n",
        "    # Se promedian los vectores de las palabras conocidas en el diccionario de embeddings.\n",
        "    # Este vector representa el significado sem치ntico de la consulta.\n",
        "    query_vector = chunk_to_vector(query_tokens, embeddings_dict)\n",
        "    print(f\"  -> Vector (embedding) de la consulta: {query_vector}\")\n",
        "    if np.all(query_vector == 0):\n",
        "        print(\"  -> AVISO: El vector de la consulta es un vector de ceros. Esto puede ocurrir si ninguna de las palabras de la consulta est치 en el diccionario de embeddings.\")\n",
        "        print(\"     La similitud coseno con un vector de ceros siempre ser치 0, lo que afectar치 los resultados de la recuperaci칩n.\")\n",
        "        print(\"     Considere a침adir m치s palabras al 'embeddings_dict' o mejorar el preprocesamiento de la consulta para palabras fuera de vocabulario.\")\n",
        "\n",
        "    print(\"\\nPaso 2: Calculando la similitud coseno con cada fragmento del corpus:\")\n",
        "    scores = []\n",
        "    for idx, chunk_vec in enumerate(chunk_vectors):\n",
        "        # Calcula la similitud coseno entre el vector de la consulta y cada vector de fragmento del corpus.\n",
        "        # Una similitud cercana a 1.0 indica alta relaci칩n sem치ntica.\n",
        "        similarity = cosine_similarity(query_vector, chunk_vec)\n",
        "        scores.append(similarity)\n",
        "        # Se muestra la similitud calculada para cada fragmento.\n",
        "        print(f\"  -> Similitud con Doc ID '{chunks[idx]['doc_id']}' ('{chunks[idx]['fragmento']}'): {similarity:.4f}\")\n",
        "    print(f\"  -> Puntuaciones de similitud de todos los fragmentos: {scores}\")\n",
        "\n",
        "    # Paso 3: Ordenar los fragmentos por similitud\n",
        "    # Los fragmentos se clasifican de mayor a menor similitud con la consulta.\n",
        "    print(\"\\nPaso 3: Ordenando los fragmentos por similitud (de mayor a menor):\")\n",
        "    ranked = sorted(\n",
        "        zip(range(len(chunks)), scores),\n",
        "        key=lambda item: item[1],\n",
        "        reverse=True\n",
        "    )\n",
        "    for rank_pos, (original_idx, score) in enumerate(ranked):\n",
        "        print(f\"  -> Rank #{rank_pos+1}: Doc ID '{chunks[original_idx]['doc_id']}' (Similitud: {score:.4f})\")\n",
        "    print(f\"  -> Lista de fragmentos clasificados (칤ndice original del chunk, puntuaci칩n de similitud): {ranked}\")\n",
        "\n",
        "    # Paso 4: Seleccionar los top_k fragmentos m치s relevantes\n",
        "    # Se eligen los 'top_k' fragmentos con las puntuaciones de similitud m치s altas.\n",
        "    print(f\"\\nPaso 4: Seleccionando los top {top_k} fragmentos m치s relevantes:\")\n",
        "    top_hits = []\n",
        "    for rank_pos, (idx, score) in enumerate(ranked[:top_k]):\n",
        "        chunk = chunks[idx]\n",
        "        hit_info = {\n",
        "            \"rank\": rank_pos + 1,\n",
        "            \"similitud\": score,\n",
        "            \"fragmento\": chunk[\"fragmento\"],\n",
        "            \"doc_id\": chunk[\"doc_id\"],\n",
        "        }\n",
        "        top_hits.append(hit_info)\n",
        "        print(f\"  -> Seleccionado #{rank_pos+1} (Similitud: {score:.4f}): Doc ID '{chunk['doc_id']}' - '{chunk['fragmento']}'\")\n",
        "\n",
        "    print(\"\\n--- FIN DEL PROCESO DE RECUPERACI칍N ---\\n\")\n",
        "    return top_hits\n",
        "\n",
        "def mostrar_resultados(pregunta, top_k=3):\n",
        "    \"\"\"Muestra los resultados de la b칰squeda de forma legible y detallada.\"\"\"\n",
        "    print(f\"\\n==== MOSTRANDO RESULTADOS PARA LA CONSULTA: '{pregunta}' (Top {top_k} fragmentos) ====\\n\")\n",
        "    resultados = retrieve(pregunta, top_k=top_k)\n",
        "\n",
        "    print(\"\\n===== RESULTADOS FINALES DE LA RECUPERACI칍N =====\\n\")\n",
        "    if not resultados:\n",
        "        print(\"No se encontraron resultados relevantes o el vector de la consulta fue nulo.\")\n",
        "        return\n",
        "\n",
        "    for pos, hit in enumerate(resultados, start=1):\n",
        "        porcentaje = round(hit[\"similitud\"] * 100, 1)\n",
        "        print(f\"-------------------- RESULTADO RECUPERADO #{pos} --------------------\")\n",
        "        print(f\"  Posici칩n (Rank): {hit['rank']}\")\n",
        "        print(f\"  Similitud con la consulta: {porcentaje}%\")\n",
        "        print(f\"  Documento ID: {hit['doc_id']}\")\n",
        "        print(f\"  Fragmento recuperado: '{hit['fragmento']}'\")\n",
        "        print(\"------------------------------------------------------------------\\n\")\n",
        "\n",
        "# Ejemplo 1: Pregunta sobre mascotas\n",
        "ejemplo1 = \"쯈u칠 son las mascotas?\"\n",
        "mostrar_resultados(ejemplo1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsi4PXa3TygU"
      },
      "source": [
        "---\n",
        "\n",
        "## Actividad pr치ctica 游눩\n",
        "\n",
        "Implementa la funci칩n `analizar_similitud_palabras` para calcular la similitud coseno entre dos palabras.\n",
        "Debe tomar dos palabras y el diccionario de embeddings, y devolver un valor flotante.\n",
        "Considera:\n",
        "   - Si alguna palabra no est치 en embeddings_dict, imprimir una advertencia y devolver 0.0.\n",
        "   - Utilizar la funci칩n `cosine_similarity` ya definida.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TTLFhsjjTygU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def analizar_similitud_palabras(palabra1: str, palabra2: str, embeddings_dict: dict) -> float:\n",
        "    \"\"\"\n",
        "    Calcula la similitud coseno entre los vectores de dos palabras dadas.\n",
        "\n",
        "    Esta funci칩n recupera los vectores (embeddings) de `palabra1` y `palabra2`\n",
        "    del `embeddings_dict` y luego calcula su similitud coseno. Si alguna de las\n",
        "    palabras no se encuentra en el diccionario, imprime una advertencia y devuelve 0.0.\n",
        "\n",
        "    Args:\n",
        "        palabra1 (str): La primera palabra para comparar.\n",
        "        palabra2 (str): La segunda palabra para comparar.\n",
        "        embeddings_dict (dict): Un diccionario donde las claves son palabras y los\n",
        "                                valores son sus respectivos vectores (embeddings) NumPy.\n",
        "\n",
        "    Returns:\n",
        "        float: El valor de similitud coseno entre las dos palabras (entre -1 y 1).\n",
        "               Devuelve 0.0 si alguna palabra no se encuentra en el `embeddings_dict`.\n",
        "    \"\"\"\n",
        "    # --- TU C칍DIGO AQU칈 ---\n",
        "    # Pista: Accede a los vectores de las palabras desde embeddings_dict\n",
        "    #       Usa la funci칩n cosine_similarity\n",
        "    #       Maneja el caso donde las palabras no existan en el diccionario.\n",
        "    pass # Elimina esta l칤nea cuando comiences a implementar la funci칩n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iKfTyHYTygU"
      },
      "source": [
        "### Paso 2: Analiza los resultados\n",
        "\n",
        "Observa las similitudes calculadas.\n",
        "- 쯇or qu칠 algunas preguntas recuperan mejor ciertos documentos?\n",
        "- 쯈u칠 pasa cuando usas palabras que no est치n en el corpus?\n",
        "- 쮿ay informaci칩n sem치ntica en los vectores?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RVdWrvcTygU",
        "outputId": "e8f98aa0-c3c2-4a3d-b24c-5f1850268a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La similitud entre mascotas y perros es None\n",
            "\n",
            "Recuerda:\n",
            "- Una similitud cercana a 1 indica que las palabras tienen un significado similar en el espacio vectorial.\n",
            "- Una similitud cercana a 0 (o negativa) indica que son muy diferentes o no relacionadas.\n",
            "- Si una palabra no est치 en el 'embeddings_dict', la funci칩n indicar치 una advertencia y devolver치 0.0 de similitud.\n"
          ]
        }
      ],
      "source": [
        "# Prueba tu implementaci칩n cambiando las palabras\n",
        "\n",
        "# Similitud entre 'mascotas' y 'perros'\n",
        "palabra1 = \"mascotas\"\n",
        "palabra2 = \"perros\"\n",
        "print(f\"La similitud entre {palabra1} y {palabra2} es {analizar_similitud_palabras(palabra1, palabra2, embeddings_dict)}\")\n",
        "\n",
        "print(\"\\nRecuerda:\\n- Una similitud cercana a 1 indica que las palabras tienen un significado similar en el espacio vectorial.\")\n",
        "print(\"- Una similitud cercana a 0 (o negativa) indica que son muy diferentes o no relacionadas.\")\n",
        "print(\"- Si una palabra no est치 en el 'embeddings_dict', la funci칩n indicar치 una advertencia y devolver치 0.0 de similitud.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}