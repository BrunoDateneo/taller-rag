{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 4 路 Integrando RAG con Chainlit\n",
    "\n",
    "En los bloques anteriores construimos la infraestructura de RAG: comprendimos el flujo, simulamos la b煤squeda vectorial, aprendimos a invocar la knowledge base en Bedrock y utilizamos la API de RAG para generar respuestas con LLM. Este bloque muestra c贸mo presentar todo ese trabajo mediante un chatbot sencillo creado con Chainlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 驴Por qu茅 utilizar Chainlit?\n",
    "\n",
    "- **Interfaz lista para usar**: en minutos tenemos un chat web funcional sin construir un front-end desde cero.\n",
    "- **Orientado a flujos conversacionales**: facilita manejar el estado de la conversaci贸n, mostrar componentes ricos (citas, tablas) y registrar interacciones.\n",
    "- **Productividad**: nos permite iterar sobre la experiencia del usuario mientras seguimos afinando el backend RAG.\n",
    "- **Integraci贸n sencilla**: basta con una funci贸n `on_chat_start` para inicializar recursos y un handler `on_message` que orqueste la recuperaci贸n y generaci贸n.\n",
    "\n",
    "En nuestra arquitectura, Chainlit ocupa la capa de presentaci贸n: recibe la pregunta del usuario, llama a nuestras funciones en Python (que a su vez invocan Bedrock) y muestra la respuesta final con las citas correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flujo general\n",
    "\n",
    "1. El usuario escribe un mensaje en el chatbot.\n",
    "2. Chainlit llama a nuestra l贸gica Python.\n",
    "3. Esa l贸gica reutiliza las funciones del Bloque 3 (`generar_con_prompt`, `mostrar_generacion`, etc.).\n",
    "4. Bedrock recupera fragmentos, genera la respuesta y nos devuelve citas.\n",
    "5. Chainlit muestra el resultado en la interfaz, dando contexto y confianza al usuario.\n",
    "\n",
    "La actividad consiste en ejecutar un chatbot prearmado, modificar par谩metros sencillos y verificar que las respuestas coinciden con lo que obtuvimos en el Bloque 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaci贸n del entorno\n",
    "\n",
    "1. Ejecuta la celda de instalaci贸n del **Bloque 0** (ya incluye las dependencias comunes).\n",
    "2. Instala Chainlit desde esta notebook si a煤n no est谩 disponible:\n",
    "\n",
    "```python\n",
    "!pip install chainlit\n",
    "```\n",
    "\n",
    "3. Aseg煤rate de que las variables `BEDROCK_KB_ID`, `BEDROCK_MODEL_ARN`, `BEDROCK_DATA_SOURCE_ID` y `AWS_REGION` permanecen configuradas (igual que en los bloques 2 y 3).\n",
    "4. Confirma que las funciones del Bloque 3 est谩n disponibles en el entorno (puedes copiar las definiciones relevantes a un m贸dulo com煤n o importarlas desde el propio notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura b谩sica del proyecto Chainlit\n",
    "\n",
    "Chainlit busca un archivo principal (por defecto `app.py`) con dos funciones:\n",
    "\n",
    "- `@cl.on_chat_start`: se ejecuta cuando el usuario abre la sesi贸n. Aqu铆 podemos cargar prompts, inicializar clientes y mostrar un mensaje de bienvenida.\n",
    "- `@cl.on_message`: se ejecuta por cada mensaje del usuario. Debe invocar nuestra l贸gica RAG y enviar la respuesta al chat.\n",
    "\n",
    "Crearemos `app.py` en el directorio ra铆z para que puedas ejecutarlo con `chainlit run app.py -w` (el flag `-w` habilita recarga autom谩tica)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivo `app.py`\n",
    "\n",
    "Puedes copiar el siguiente ejemplo en tu proyecto (no se editan archivos desde la notebook para evitar conflictos, pero si lo prefieres crea el fichero manualmente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "import chainlit as cl\n",
    "\n",
    "from rag_runtime import generar_con_prompt, DEFAULT_PROMPT_TEMPLATE\n",
    "from rag_runtime import mostrar_generacion_simple\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = os.getenv(\"CHAINLIT_PROMPT_TEMPLATE\", DEFAULT_PROMPT_TEMPLATE)\n",
    "\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(\n",
    "        content=(\n",
    "            \"Hola  Soy el asistente interno. Puedes hacer preguntas sobre la documentaci贸n\"\n",
    "            \" corporativa y citar茅 las fuentes si est谩n disponibles.\"\n",
    "        )\n",
    "    ).send()\n",
    "\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: cl.Message):\n",
    "    pregunta = message.content\n",
    "    await cl.Message(content=\"Procesando tu pregunta...\").send()\n",
    "\n",
    "    respuesta = generar_con_prompt(pregunta, PROMPT_TEMPLATE)\n",
    "    texto, citas = mostrar_generacion_simple(respuesta)\n",
    "\n",
    "    await cl.Message(content=texto, author=\"Asistente RAG\").send()\n",
    "\n",
    "    if citas:\n",
    "        citas_md = \"\\n\".join(f\"- {cita}\" for cita in citas)\n",
    "        await cl.Message(content=f\"Fuentes:\\n{citas_md}\").send()\n",
    "```\n",
    "\n",
    "Notas:\n",
    "- `rag_runtime` representa un m贸dulo reutilizable donde puedes colocar las funciones del Bloque 3 (`generar_con_prompt` y una variante de `mostrar_generacion` que devuelva texto y citas).\n",
    "- Para mantener el notebook conciso, solo mostramos un helper `mostrar_generacion_simple` que transforma la respuesta en texto y una lista de citas (puedes implementarlo igual que en el Bloque 3).\n",
    "- `CHAINLIT_PROMPT_TEMPLATE` permite experimentar con prompts sin editar el c贸digo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad 路 Ejecutar el chatbot y validar la integraci贸n\n",
    "\n",
    "1. Copia `app.py` en la ra铆z del proyecto junto con el m贸dulo `rag_runtime.py` (que puede contener las funciones del Bloque 3).\n",
    "2. En una terminal, ejecuta:\n",
    "   ```bash\n",
    "   chainlit run app.py -w\n",
    "   ```\n",
    "3. Abre el enlace que Chainlit mostrar谩 en la consola (usualmente `http://localhost:8000`).\n",
    "4. Haz preguntas similares a las de los bloques anteriores y comprueba que las respuestas coinciden con lo esperado y que se muestran las citas.\n",
    "5. Modifica la variable `CHAINLIT_PROMPT_TEMPLATE` o las funciones de `rag_runtime` para personalizar el comportamiento.\n",
    "\n",
    "La actividad no requiere construir el chatbot desde cero; el objetivo es entender c贸mo conectar los componentes y verificar que funcionan de punta a punta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensiones sugeridas\n",
    "\n",
    "- Mostrar el top de fragmentos recuperados en tarjetas Chainlit antes de la respuesta final.\n",
    "- Agregar botones de seguimiento (por ejemplo, \"Agregar documento\" o \"Reintentar con otro prompt\").\n",
    "- Integrar m茅tricas de uso u observabilidad para monitorear las conversaciones.\n",
    "- Configurar autenticaci贸n para restringir el acceso al chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rol de Chainlit en la arquitectura\n",
    "\n",
    "Resumiendo:\n",
    "- **Recuperaci贸n y generaci贸n** (Bloques 2 y 3) siguen viviendo en Python y Bedrock.\n",
    "- **Chainlit** act煤a como la interfaz conversacional que conecta a nuestros usuarios con el flujo RAG.\n",
    "- Este patr贸n desacopla la l贸gica del chatbot del front-end, lo que facilita experimentar con prompts, cambiar modelos o a帽adir nuevas fuentes sin reescribir la interfaz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr贸ximos pasos\n",
    "\n",
    "- Consolidar las funciones de recuperaci贸n y generaci贸n en un paquete o m贸dulo reutilizable.\n",
    "- A帽adir controles adicionales (por ejemplo, manejo de errores m谩s detallado o logging).\n",
    "- Preparar un entorno de demostraci贸n/producci贸n en la nube para que el equipo pueda probar el chatbot sin depender de notebooks.\n",
    "- Evaluar la necesidad de moderaci贸n de contenidos y pol铆ticas de seguridad antes de liberar el asistente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
