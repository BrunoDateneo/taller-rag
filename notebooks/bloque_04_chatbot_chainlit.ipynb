{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 4 ¬∑ De RAG a Chatbot: La Capa de Presentaci√≥n\n",
    "\n",
    "En los bloques anteriores exploramos los componentes fundamentales de RAG: comprendimos el flujo completo, simulamos la b√∫squeda vectorial, aprendimos a invocar knowledge bases en Bedrock y utilizamos la API de RAG para generar respuestas con LLM. Este bloque se enfoca en c√≥mo integrar toda esa infraestructura en una interfaz conversacional que permita a los usuarios interactuar de forma natural con el sistema RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La necesidad de una interfaz conversacional\n",
    "\n",
    "Una vez que tenemos un sistema RAG funcional capaz de recuperar informaci√≥n relevante y generar respuestas coherentes, el siguiente paso natural es exponerlo a trav√©s de una interfaz que permita a los usuarios interactuar de manera intuitiva. Un chatbot conversacional es la forma m√°s natural de presentar un sistema RAG porque:\n",
    "\n",
    "- **Interacci√≥n natural**: Los usuarios pueden hacer preguntas en lenguaje natural, similar a c√≥mo interactuar√≠an con un experto humano\n",
    "- **Feedback inmediato**: Las respuestas se generan en tiempo real, permitiendo una conversaci√≥n fluida\n",
    "- **Transparencia**: Puede mostrar las fuentes y citas que respaldan cada respuesta, generando confianza\n",
    "- **Escalabilidad**: Un solo chatbot puede atender m√∫ltiples usuarios simult√°neamente\n",
    "\n",
    "## ¬øQu√© es Chainlit?\n",
    "\n",
    "Chainlit es un framework de Python dise√±ado espec√≠ficamente para construir interfaces conversacionales con modelos de IA. Su filosof√≠a se basa en:\n",
    "\n",
    "- **Simplicidad**: Permite crear chatbots web funcionales con m√≠nima configuraci√≥n, sin necesidad de construir un front-end desde cero\n",
    "- **Orientaci√≥n a flujos conversacionales**: Facilita el manejo del estado de la conversaci√≥n, la presentaci√≥n de componentes ricos (citas, tablas, visualizaciones) y el registro de interacciones\n",
    "- **Productividad**: Permite iterar r√°pidamente sobre la experiencia del usuario mientras se sigue afinando el backend RAG\n",
    "- **Integraci√≥n sencilla**: Utiliza decoradores simples (`@cl.on_chat_start`, `@cl.on_message`) para definir el comportamiento del chatbot\n",
    "\n",
    "En nuestra arquitectura, Chainlit ocupa la **capa de presentaci√≥n**: recibe la pregunta del usuario, invoca nuestras funciones Python (que a su vez llaman a Bedrock), y presenta la respuesta final junto con las citas correspondientes de manera visual y accesible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura del flujo completo\n",
    "\n",
    "El flujo de un chatbot RAG con Chainlit sigue una arquitectura en capas bien definida:\n",
    "\n",
    "### 1. Capa de presentaci√≥n (Chainlit)\n",
    "- **Recepci√≥n de mensajes**: El usuario escribe una pregunta en la interfaz web\n",
    "- **Gesti√≥n de sesi√≥n**: Chainlit mantiene el contexto de la conversaci√≥n\n",
    "- **Renderizado de respuestas**: Presenta el texto generado y las citas de forma visual\n",
    "\n",
    "### 2. Capa de orquestaci√≥n (Python)\n",
    "- **Procesamiento de entrada**: Recibe la pregunta del usuario desde Chainlit\n",
    "- **Invocaci√≥n de RAG**: Llama a las funciones que implementan el flujo RAG (recuperaci√≥n + generaci√≥n)\n",
    "- **Procesamiento de salida**: Extrae el texto generado y las citas de la respuesta de Bedrock\n",
    "- **Formateo**: Prepara la informaci√≥n para su presentaci√≥n en Chainlit\n",
    "\n",
    "### 3. Capa de servicios (AWS Bedrock)\n",
    "- **Recuperaci√≥n**: Busca fragmentos relevantes en la knowledge base usando b√∫squeda vectorial\n",
    "- **Generaci√≥n**: El LLM sintetiza una respuesta basada en los fragmentos recuperados\n",
    "- **Trazabilidad**: Devuelve citas que vinculan cada parte de la respuesta con sus fuentes\n",
    "\n",
    "### Flujo de datos\n",
    "\n",
    "```\n",
    "Usuario ‚Üí Chainlit ‚Üí Funci√≥n Python ‚Üí Bedrock API ‚Üí Knowledge Base\n",
    "                                                          ‚Üì\n",
    "Usuario ‚Üê Chainlit ‚Üê Funci√≥n Python ‚Üê Respuesta + Citas ‚Üê\n",
    "```\n",
    "\n",
    "Este dise√±o desacopla las responsabilidades: la l√≥gica RAG permanece independiente de la interfaz, lo que facilita experimentar con diferentes frameworks de UI, cambiar modelos, o agregar nuevas funcionalidades sin reescribir todo el sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes clave de un chatbot RAG\n",
    "\n",
    "Para construir un chatbot que integre RAG, necesitamos combinar varios componentes:\n",
    "\n",
    "### Funciones de RAG (del Bloque 3)\n",
    "- **`generar_con_prompt()`**: Encapsula la l√≥gica de invocaci√≥n a `retrieve_and_generate` de Bedrock\n",
    "- **`mostrar_generacion_simple()`**: Versi√≥n adaptada que extrae texto y citas para presentaci√≥n en UI\n",
    "- **`DEFAULT_PROMPT_TEMPLATE`**: Template que gu√≠a al LLM sobre c√≥mo usar el contexto recuperado\n",
    "\n",
    "### Handlers de Chainlit\n",
    "- **`@cl.on_chat_start`**: Se ejecuta cuando un usuario inicia una sesi√≥n. Ideal para:\n",
    "  - Inicializar recursos (clientes de AWS, cargar configuraci√≥n)\n",
    "  - Mostrar mensaje de bienvenida\n",
    "  - Establecer el contexto inicial de la conversaci√≥n\n",
    "\n",
    "- **`@cl.on_message`**: Se ejecuta por cada mensaje del usuario. Debe:\n",
    "  - Extraer la pregunta del mensaje\n",
    "  - Invocar la funci√≥n RAG con los par√°metros apropiados\n",
    "  - Procesar la respuesta y extraer texto y citas\n",
    "  - Enviar la respuesta formateada de vuelta al usuario\n",
    "\n",
    "### Configuraci√≥n y variables\n",
    "- **Variables de entorno**: Para mantener configuraci√≥n flexible (knowledge base ID, modelo ARN, regi√≥n AWS)\n",
    "- **Credenciales AWS**: Autenticaci√≥n para acceder a Bedrock (pueden venir de variables de entorno, archivos de credenciales, o roles IAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flujo de ejecuci√≥n del chatbot\n",
    "\n",
    "Cuando un usuario interact√∫a con el chatbot, se ejecuta el siguiente flujo:\n",
    "\n",
    "### Inicio de sesi√≥n (`on_chat_start`)\n",
    "1. Chainlit detecta que un usuario abre el chat\n",
    "2. Se ejecuta la funci√≥n decorada con `@cl.on_chat_start`\n",
    "3. Se inicializan recursos (si es necesario) y se env√≠a mensaje de bienvenida\n",
    "4. El usuario ve la interfaz lista para recibir preguntas\n",
    "\n",
    "### Procesamiento de mensajes (`on_message`)\n",
    "1. **Recepci√≥n**: El usuario escribe una pregunta y Chainlit captura el mensaje\n",
    "2. **Indicador de carga**: Se muestra un mensaje temporal \"Procesando...\" para dar feedback inmediato\n",
    "3. **Invocaci√≥n RAG**: Se llama a `generar_con_prompt()` con la pregunta del usuario\n",
    "4. **Procesamiento en Bedrock**:\n",
    "   - La pregunta se convierte en embedding\n",
    "   - Se buscan fragmentos similares en la knowledge base\n",
    "   - El LLM genera una respuesta usando esos fragmentos\n",
    "   - Se devuelven citas que vinculan la respuesta con las fuentes\n",
    "5. **Extracci√≥n**: `mostrar_generacion_simple()` procesa la respuesta y separa texto de citas\n",
    "6. **Presentaci√≥n**: Se env√≠an dos mensajes:\n",
    "   - La respuesta principal del asistente\n",
    "   - Las fuentes consultadas (si existen)\n",
    "\n",
    "### Manejo de errores\n",
    "Es importante incluir manejo de excepciones para:\n",
    "- Errores de conexi√≥n con AWS\n",
    "- Timeouts en la API\n",
    "- Respuestas vac√≠as o inv√°lidas\n",
    "- Problemas de autenticaci√≥n\n",
    "\n",
    "Esto garantiza que el usuario siempre reciba feedback, incluso cuando algo falla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen: Arquitectura completa de extremo a extremo\n",
    "\n",
    "Hemos recorrido todo el flujo de un sistema RAG completo:\n",
    "\n",
    "### Capas del sistema\n",
    "\n",
    "1. **Capa de datos** (Bloque 1)\n",
    "   - Documentos fuente almacenados en S3\n",
    "   - Knowledge base con embeddings vectoriales\n",
    "   - Metadatos para trazabilidad\n",
    "\n",
    "2. **Capa de recuperaci√≥n** (Bloque 2)\n",
    "   - B√∫squeda vectorial sem√°ntica\n",
    "   - Ranking por similitud\n",
    "   - Extracci√≥n de fragmentos relevantes\n",
    "\n",
    "3. **Capa de generaci√≥n** (Bloque 3)\n",
    "   - LLM que sintetiza respuestas\n",
    "   - Prompt engineering para guiar el comportamiento\n",
    "   - Generaci√≥n de citas y trazabilidad\n",
    "\n",
    "4. **Capa de presentaci√≥n** (Bloque 4)\n",
    "   - Interfaz conversacional con Chainlit\n",
    "   - Visualizaci√≥n de respuestas y fuentes\n",
    "   - Gesti√≥n de sesiones y estado\n",
    "\n",
    "### Principios de dise√±o\n",
    "\n",
    "- **Desacoplamiento**: Cada capa es independiente y puede evolucionar por separado\n",
    "- **Reutilizaci√≥n**: Las funciones de RAG pueden usarse en m√∫ltiples contextos (notebooks, APIs, chatbots)\n",
    "- **Trazabilidad**: Siempre sabemos qu√© fuentes respaldan cada respuesta\n",
    "- **Flexibilidad**: F√°cil cambiar modelos, prompts, o interfaces sin reescribir todo\n",
    "\n",
    "Este patr√≥n arquitect√≥nico permite construir sistemas RAG robustos, escalables y mantenibles que pueden adaptarse a diferentes necesidades y evolucionar con el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividad Pr√°ctica\n",
    "\n",
    "En esta secci√≥n vamos a trabajar paso a paso para construir un chatbot RAG completo con Chainlit. Vamos a partir de una versi√≥n m√≠nima funcional y la vamos a ir mejorando hasta llegar a una implementaci√≥n m√°s completa.\n",
    "\n",
    "### Estructura de los ejercicios\n",
    "\n",
    "Los ejercicios est√°n dise√±ados en orden de complejidad creciente. Cada ejercicio agrega funcionalidad sobre el anterior, permitiendo que entiendas cada componente antes de avanzar al siguiente nivel.\n",
    "\n",
    "**Archivo de referencia:**\n",
    "- `chatbot/chatbot_chainlit.py`: Versi√≥n m√≠nima funcional (punto de partida)\n",
    "\n",
    "---\n",
    "\n",
    "### Ejercicio 1: Configurar entorno y ejecutar el bot b√°sico\n",
    "\n",
    "**Objetivo:** Configurar el entorno de desarrollo y ejecutar la versi√≥n m√≠nima del chatbot.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. **Cre√° un entorno virtual:**\n",
    "   ```bash\n",
    "   python -m venv taller-rag\n",
    "   ```\n",
    "\n",
    "2. **Activ√° el entorno virtual:**\n",
    "   - En Windows: `taller-rag\\Scripts\\activate`\n",
    "   - En Linux/Mac: `source taller-rag/bin/activate`\n",
    "\n",
    "3. **Instal√° dependencias desde `requirements.txt`:**\n",
    "   ```bash\n",
    "   pip install -r chatbot/requirements.txt\n",
    "   ```\n",
    "\n",
    "4. **Revis√° el c√≥digo base:**\n",
    "   abr√≠ `chatbot/chatbot_chainlit.py` y familiarizate con su estructura:\n",
    "   - Configuraci√≥n de AWS\n",
    "   - Funci√≥n `generar_con_prompt()`\n",
    "   - Handlers de Chainlit (`on_chat_start`, `on_message`)\n",
    "\n",
    "5. **Configurar credenciales AWS:**\n",
    "   Por ahora, vamos a hardcodear las credenciales directamente en el c√≥digo (en el ejercicio final las refactorizamos). Edit√° `chatbot/chatbot_chainlit.py` y reemplaz√° los valores de `os.getenv()` con tus credenciales reales:\n",
    "   ```python\n",
    "   # TODO: Reemplazar los valores de os.getenv() con tus credenciales reales\n",
    "   # Por ahora hardcodeamos las credenciales (en \"Pasos a seguir\" las refactorizamos)\n",
    "   session = boto3.Session(\n",
    "       aws_access_key_id=\"TU_ACCESS_KEY_ID\",  # Reemplaz√° con tu access key ID\n",
    "       aws_secret_access_key=\"TU_SECRET_ACCESS_KEY\",  # Reemplaz√° con tu secret access key\n",
    "       aws_session_token=\"TU_SESSION_TOKEN\"  # Reemplaz√° con tu session token (si us√°s credenciales temporales)\n",
    "   )\n",
    "   \n",
    "   # Tambi√©n pod√©s verificar que las constantes est√©n configuradas:\n",
    "   # AWS_REGION = \"us-west-2\"  # o la regi√≥n que corresponda\n",
    "   # KNOWLEDGE_BASE_ID = \"TU_KB_ID\"  # Tu Knowledge Base ID\n",
    "   # MODEL_ARN = \"us.deepseek.r1-v1:0\"  # El modelo que quer√©s usar\n",
    "   ```\n",
    "   \n",
    "   **üí° Pista:** si no ten√©s credenciales AWS, pod√©s obtenerlas desde la consola de AWS o usando el comando `aws configure` si ten√©s AWS CLI instalado.\n",
    "\n",
    "6. **Ejecut√° el chatbot:**\n",
    "   ```bash\n",
    "   chainlit run chatbot/chatbot_chainlit.py -w\n",
    "   ```\n",
    "\n",
    "7. **Prob√° el chatbot:**\n",
    "   - abr√≠ el navegador en la URL que Chainlit muestra (t√≠picamente `http://localhost:8000`)\n",
    "   - hac√© algunas preguntas sobre RAG y verific√° que el bot responda correctamente\n",
    "\n",
    "**‚úÖ Criterio de √©xito:** El chatbot se ejecuta sin errores y responde preguntas b√°sicas.\n",
    "\n",
    "---\n",
    "\n",
    "### Ejercicio 2: Extraer y mostrar citas b√°sicas\n",
    "\n",
    "**Objetivo:** extraer informaci√≥n de citas de la respuesta de Bedrock y mostrarlas al usuario.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. **Cre√° la funci√≥n `extraer_citas_completas()`:** esta funci√≥n tiene que procesar el campo `citations` de la respuesta de Bedrock y extraer:\n",
    "   - El texto citado (span)\n",
    "   - Las referencias (fuentes) que respaldan cada cita\n",
    "   - Las URIs de las fuentes\n",
    "\n",
    "2. **Modific√° `on_message` para mostrar citas:** despu√©s de mostrar la respuesta principal, mostr√° las fuentes consultadas.\n",
    "\n",
    "3. **Formato b√°sico de citas:** por ahora, mostr√° las citas como una lista simple de URIs o texto plano. En el siguiente ejercicio vamos a mejorar la visualizaci√≥n.\n",
    "\n",
    "**üí° Pista:** revis√° la estructura de la respuesta de `retrieve_and_generate` en el Bloque 3 para entender c√≥mo est√°n organizadas las citas.\n",
    "\n",
    "**‚úÖ Criterio de √©xito:** El chatbot muestra las fuentes que respaldan cada respuesta.\n",
    "\n",
    "---\n",
    "\n",
    "### Ejercicio 3: Agregar logging b√°sico\n",
    "\n",
    "**Objetivo:** implementar logging para facilitar el debugging y monitoreo del chatbot.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. **Configur√° logging al inicio del archivo:**\n",
    "   ```python\n",
    "   import logging\n",
    "   \n",
    "   logging.basicConfig(\n",
    "       level=logging.INFO,\n",
    "       format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "       handlers=[\n",
    "           logging.FileHandler('chatbot.log', encoding='utf-8'),\n",
    "           logging.StreamHandler()\n",
    "       ]\n",
    "   )\n",
    "   logger = logging.getLogger(__name__)\n",
    "   ```\n",
    "\n",
    "2. **Agreg√° logs en puntos clave:**\n",
    "   - al iniciar sesi√≥n (`on_chat_start`)\n",
    "   - al recibir una pregunta (`on_message`)\n",
    "   - antes y despu√©s de llamar a Bedrock (`generar_con_prompt`)\n",
    "   - al procesar errores\n",
    "\n",
    "3. **Prob√° y revis√° los logs:** ejecut√° el chatbot y verific√° que los logs se escriban correctamente en `chatbot.log` y en la consola.\n",
    "\n",
    "**‚úÖ Criterio de √©xito:** Los logs capturan informaci√≥n relevante sobre el flujo de ejecuci√≥n y errores.\n",
    "\n",
    "---\n",
    "\n",
    "### Ejercicio 4: Integrar componente JSX para citas interactivas\n",
    "\n",
    "**Objetivo:** integrar el componente JSX existente en el chatbot para mostrar citas de forma elegante e interactiva.\n",
    "\n",
    "#### ¬øQu√© es JSX?\n",
    "\n",
    "JSX (JavaScript XML) es una extensi√≥n de sintaxis de JavaScript que permite escribir c√≥digo que se parece a HTML dentro de JavaScript. En el contexto de Chainlit, los componentes JSX permiten crear elementos visuales personalizados para la interfaz del chatbot usando React.\n",
    "\n",
    "Un componente JSX es b√°sicamente una funci√≥n que recibe datos (llamados \"props\") y retorna elementos visuales. Por ejemplo, el componente `Citations.jsx` que ya existe en `chatbot/public/elements/Citations.jsx` recibe una lista de citas y las muestra en un formato interactivo con acordeones desplegables.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. **Revis√° el componente existente:** el archivo `chatbot/public/elements/Citations.jsx` ya contiene un componente React que muestra las citas de forma interactiva. Abr√≠ el archivo y familiarizate con su estructura para entender qu√© datos espera recibir.\n",
    "\n",
    "2. **Integr√° el componente en Python:** modific√° tu funci√≥n `on_message` para usar `cl.CustomElement` y pasar las citas al componente JSX:\n",
    "   ```python\n",
    "   # Despu√©s de extraer las citas con extraer_citas_completas()\n",
    "   if citas_completas:\n",
    "       citations_element = cl.CustomElement(\n",
    "           name=\"Citations\",\n",
    "           props={\"citations\": citas_completas}\n",
    "       )\n",
    "       await cl.Message(\n",
    "           content=\"\",\n",
    "           elements=[citations_element],\n",
    "           author=\"Asistente RAG\"\n",
    "       ).send()\n",
    "   ```\n",
    "\n",
    "3. **Verific√° el formato de datos:** asegurate de que `citas_completas` tenga el formato correcto que espera el componente JSX. Cada cita debe tener:\n",
    "   - `citation_index`: n√∫mero de la cita\n",
    "   - `texto_citado`: el texto que est√° siendo citado\n",
    "   - `span_start` y `span_end`: posiciones del span\n",
    "   - `referencias`: lista de referencias con `source` y `content`\n",
    "\n",
    "4. **Prob√° la visualizaci√≥n:** ejecut√° el chatbot y verific√° que las citas se muestren correctamente en formato colapsable y que se puedan expandir para ver detalles.\n",
    "\n",
    "**üí° Pista:** el componente JSX espera recibir las citas en el mismo formato que retorna `extraer_citas_completas()`, as√≠ que solo necesit√°s pasarle directamente el resultado de esa funci√≥n.\n",
    "\n",
    "**‚úÖ Criterio de √©xito:** Las citas se muestran en un formato visual interactivo y profesional usando el componente JSX.\n",
    "\n",
    "---\n",
    "\n",
    "## Pasos a seguir\n",
    "\n",
    "Una vez completados los ejercicios anteriores, te recomendamos implementar estas mejoras adicionales para hacer tu chatbot m√°s robusto y profesional:\n",
    "\n",
    "### Variables de entorno\n",
    "\n",
    "**Objetivo:** mejorar la seguridad y flexibilidad del c√≥digo usando variables de entorno en lugar de credenciales hardcodeadas.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. **Identific√° los valores hardcodeados:**\n",
    "   - Credenciales AWS (access key, secret key, session token)\n",
    "   - Knowledge Base ID\n",
    "   - Model ARN\n",
    "   - AWS Region\n",
    "\n",
    "2. **Refactoriz√° para usar `os.getenv()`:** agreg√° c√≥digo para leer las variables de entorno en lugar de valores hardcodeados:\n",
    "   ```python\n",
    "   AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "   AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "   AWS_SESSION_TOKEN = os.getenv(\"AWS_SESSION_TOKEN\")\n",
    "   KNOWLEDGE_BASE_ID = os.getenv(\"BEDROCK_KB_ID\")\n",
    "   MODEL_ARN = os.getenv(\"BEDROCK_MODEL_ARN\")\n",
    "   AWS_REGION = os.getenv(\"AWS_REGION\", \"us-west-2\")\n",
    "   ```\n",
    "\n",
    "3. **Cre√° un archivo `.env` de ejemplo:** document√° qu√© variables de entorno son necesarias.\n",
    "\n",
    "4. **Actualiz√° la documentaci√≥n:** agreg√° instrucciones sobre c√≥mo configurar las variables de entorno.\n",
    "\n",
    "### Manejo de errores\n",
    "\n",
    "**Objetivo:** agregar manejo de errores m√°s espec√≠fico y mensajes informativos para el usuario.\n",
    "\n",
    "**Pasos:**\n",
    "\n",
    "1. **Identific√° tipos de errores comunes:**\n",
    "   - Errores de autenticaci√≥n AWS\n",
    "   - Errores de conexi√≥n/timeout\n",
    "   - Errores de la API de Bedrock\n",
    "   - Respuestas vac√≠as o inv√°lidas\n",
    "\n",
    "2. **Modific√° `on_message` para manejar errores espec√≠ficos:**\n",
    "   ```python\n",
    "   @cl.on_message\n",
    "   async def on_message(message: cl.Message):\n",
    "       try:\n",
    "           respuesta = generar_con_prompt(message.content)\n",
    "           texto = respuesta.get(\"output\", {}).get(\"text\", \"<Sin respuesta>\")\n",
    "           \n",
    "           if not texto or texto == \"<Sin respuesta>\":\n",
    "               await cl.Message(content=\"‚ùå No se pudo generar una respuesta v√°lida.\", author=\"Sistema\").send()\n",
    "               return\n",
    "               \n",
    "           await cl.Message(content=texto, author=\"Asistente RAG\").send()\n",
    "       except cliente.exceptions.ClientError as e:\n",
    "           # Manejar errores espec√≠ficos de AWS\n",
    "           await cl.Message(content=f\"‚ùå Error de AWS: {str(e)}\", author=\"Sistema\").send()\n",
    "       except Exception as e:\n",
    "           # Manejar otros errores\n",
    "           await cl.Message(content=f\"‚ùå Error: {str(e)}\", author=\"Sistema\").send()\n",
    "   ```\n",
    "\n",
    "3. **Agreg√° validaci√≥n de respuesta vac√≠a:** verific√° que la respuesta contenga texto antes de enviarla al usuario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
