{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bloque 2 · Conectando RAG con la nube\n",
        "\n",
        "En este bloque daremos el salto de la simulación local a un servicio en la nube. Presentaremos conceptos básicos de computación en la nube, APIs y Amazon Bedrock, para luego analizar cómo luce la respuesta del endpoint `Retrieve` cuando contamos con una knowledge base ya configurada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## De la simulación a la nube\n",
        "\n",
        "- En el **Bloque 0** visualizamos la arquitectura completa y los objetivos del proyecto.\n",
        "- En el **Bloque 1** exploramos la recuperación basada en similitud con una simulación local.\n",
        "\n",
        "Ahora nos enfocamos en cómo un servicio administrado nos ayuda a escalar esa lógica, manteniendo el hilo conductor: recuperar fragmentos relevantes para enriquecer respuestas generadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conceptos clave: nube y APIs\n",
        "\n",
        "- **Computación en la nube**: consumo de recursos (cómputo, almacenamiento, modelos) como servicios bajo demanda, sin gestionar infraestructura física.\n",
        "- **API (Application Programming Interface)**: conjunto de reglas para que dos sistemas se comuniquen. Usualmente exponemos recursos vía URLs (endpoints) que aceptan solicitudes con parámetros y devuelven respuestas estructuradas (JSON).\n",
        "- **Endpoint**: dirección específica de una API que realiza una acción. Por ejemplo, `Retrieve` es un endpoint que consulta una base de conocimiento con una pregunta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ¿Qué ofrece Amazon Bedrock?\n",
        "\n",
        "Amazon Bedrock es un servicio administrado que permite acceder a modelos fundacionales (propios y de terceros) mediante una API unificada. Para nuestro flujo RAG, destacamos:\n",
        "- **Modelos de embeddings** para convertir texto en vectores.\n",
        "- **Modelos generativos** para elaborar respuestas.\n",
        "- **Knowledge bases** que almacenan representaciones vectoriales y resuelven la recuperación de forma administrada.\n",
        "- **Integración con otras herramientas AWS** (S3, IAM, CloudWatch) que facilitan la operación en producción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Knowledge Bases en Bedrock\n",
        "\n",
        "Una *knowledge base* es un repositorio vectorial que Bedrock administra por nosotros. Sus componentes principales son:\n",
        "- **Fuentes de datos**: conjuntos de documentos almacenados, por ejemplo, en Amazon S3. Podemos proveer manuales, políticas, FAQs, etc.\n",
        "- **Pipelines de ingesta**: procesos que limpian, fragmentan y generan embeddings de cada documento.\n",
        "- **Catálogo de metadatos**: guarda referencias al origen de cada fragmento (ruta de archivo, sección, versión) para poder citar las fuentes en las respuestas.\n",
        "\n",
        "Asumimos que la organización ya configuró la knowledge base y ejecutó al menos una ingesta para tener información disponible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Endpoint `Retrieve`\n",
        "\n",
        "- Recibe una **pregunta** o consulta en texto.\n",
        "- Calcula embeddings con el modelo elegido.\n",
        "- Busca los fragmentos más relevantes en la knowledge base.\n",
        "- Devuelve un listado ordenado de resultados con puntuaciones, contenido y metadatos.\n",
        "\n",
        "Esta respuesta luego se utiliza para generar una contestación final (por ejemplo, desde Chainlit) o simplemente para mostrar evidencias al usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Actividad práctica · Paseo por la respuesta de `Retrieve`\n",
        "\n",
        "Simularemos la respuesta JSON que entrega Bedrock cuando invocamos el endpoint `Retrieve`. Analizaremos cada campo para entender qué información recibimos y cómo podemos utilizarla en nuestro chatbot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import textwrap\n",
        "from typing import Dict, Any\n",
        "\n",
        "retrieve_response: Dict[str, Any] = {\n",
        "    \"knowledgeBaseId\": \"kb-1234567890\",\n",
        "    \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2\",\n",
        "    \"query\": \"¿Cómo prepara Bedrock una knowledge base para responder preguntas?\",\n",
        "    \"retrievalResults\": [\n",
        "        {\n",
        "            \"score\": 0.83,\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"text\": (\n",
        "                        \"Durante la ingesta, Bedrock normaliza el texto, lo divide en chunks y genera \"\n",
        "                        \"embeddings con el modelo seleccionado. Los vectores se almacenan en un índice \"\n",
        "                        \"optimizado para búsquedas de similitud.\"\n",
        "                    )\n",
        "                }\n",
        "            ],\n",
        "            \"metadata\": {\n",
        "                \"title\": \"Guía de operación RAG\",\n",
        "                \"source\": \"s3://org-knowledge/rag/guia-operacion.pdf\",\n",
        "                \"chunkId\": \"guia-operacion.pdf:12\",\n",
        "                \"authors\": [\"Equipo Datos\"],\n",
        "            },\n",
        "            \"location\": {\n",
        "                \"type\": \"S3\",\n",
        "                \"s3Location\": {\n",
        "                    \"uri\": \"s3://org-knowledge/rag/guia-operacion.pdf\",\n",
        "                    \"region\": \"us-east-1\",\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"score\": 0.74,\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"text\": (\n",
        "                        \"Una knowledge base puede conectarse a múltiples fuentes. Cada ejecución \"\n",
        "                        \"de ingesta detecta cambios y actualiza embeddings para mantener la información al día.\"\n",
        "                    )\n",
        "                }\n",
        "            ],\n",
        "            \"metadata\": {\n",
        "                \"title\": \"Procedimiento de ingesta\",\n",
        "                \"source\": \"s3://org-knowledge/rag/procedimiento-ingesta.md\",\n",
        "                \"chunkId\": \"procedimiento-ingesta.md:05\",\n",
        "            },\n",
        "            \"location\": {\n",
        "                \"type\": \"S3\",\n",
        "                \"s3Location\": {\n",
        "                    \"uri\": \"s3://org-knowledge/rag/procedimiento-ingesta.md\",\n",
        "                    \"region\": \"us-east-1\",\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"score\": 0.65,\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"text\": (\n",
        "                        \"Las respuestas generadas pueden incluir citas apuntando a los fragmentos recuperados. \"\n",
        "                        \"Esto aumenta la transparencia para el usuario final.\"\n",
        "                    )\n",
        "                }\n",
        "            ],\n",
        "            \"metadata\": {\n",
        "                \"title\": \"Diseño del chatbot\",\n",
        "                \"source\": \"s3://org-knowledge/rag/diseño-chatbot.docx\",\n",
        "                \"chunkId\": \"diseño-chatbot.docx:07\",\n",
        "            },\n",
        "            \"location\": {\n",
        "                \"type\": \"S3\",\n",
        "                \"s3Location\": {\n",
        "                    \"uri\": \"s3://org-knowledge/rag/diseño-chatbot.docx\",\n",
        "                    \"region\": \"us-east-1\",\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "    ],\n",
        "    \"nextToken\": None,\n",
        "}\n",
        "\n",
        "print(\"Consulta simulada:\")\n",
        "print(retrieve_response[\"query\"])\n",
        "print(\"\\nTotal de resultados:\", len(retrieve_response[\"retrievalResults\"]))\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observa que la respuesta incluye:\n",
        "- El identificador de la knowledge base utilizada.\n",
        "- El ARN del modelo de embeddings.\n",
        "- La pregunta original (`query`).\n",
        "- Un arreglo de `retrievalResults` con puntajes (`score`), contenido y metadatos.\n",
        "- Información de la ubicación del documento para citar la fuente.\n",
        "\n",
        "Exploraremos cada resultado para entender qué datos podemos mostrar al usuario o reutilizar en procesos posteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def mostrar_resultados(respuesta: Dict[str, Any], max_ancho: int = 96) -> None:\n",
        "    for idx, resultado in enumerate(respuesta.get(\"retrievalResults\", []), start=1):\n",
        "        score = round(resultado.get(\"score\", 0.0) * 100, 2)\n",
        "        metadatos = resultado.get(\"metadata\", {})\n",
        "        texto = resultado.get(\"content\", [{}])[0].get(\"text\", \"\")\n",
        "\n",
        "        print(f\"Resultado #{idx}\")\n",
        "        print(f\"Similitud: {score}%\")\n",
        "        print(f\"Título: {metadatos.get('title', 'Sin título')}\")\n",
        "        print(f\"Fuente: {metadatos.get('source', 'Sin referencia')}\")\n",
        "        print(\"Fragmento:\")\n",
        "        for linea in textwrap.wrap(texto, width=max_ancho):\n",
        "            print(f\"  {linea}\")\n",
        "        print(\"-\" * max_ancho)\n",
        "\n",
        "mostrar_resultados(retrieve_response)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimenta\n",
        "\n",
        "- Ajusta el contenido de `retrieve_response` para simular resultados de otra pregunta.\n",
        "- Agrega metadatos propios (por ejemplo, etiquetas de seguridad o fechas).\n",
        "- Observa cómo podrías transformar esta información en tarjetas dentro de una interfaz Chainlit o en citas dentro de una respuesta generada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Próximos pasos\n",
        "\n",
        "En el siguiente bloque conectaremos esta recuperación con un modelo generativo en Bedrock y construiremos la interacción en Chainlit, reutilizando los fragmentos y metadatos que acabamos de analizar."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}